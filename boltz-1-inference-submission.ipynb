{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":12024591,"sourceType":"competition"},{"sourceId":5123458,"sourceType":"datasetVersion","datasetId":2975803},{"sourceId":10880419,"sourceType":"datasetVersion","datasetId":6760509},{"sourceId":10923077,"sourceType":"datasetVersion","datasetId":6785143},{"sourceId":11695366,"sourceType":"datasetVersion","datasetId":6791615}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T15:59:51.571059Z","iopub.execute_input":"2025-05-07T15:59:51.571353Z","iopub.status.idle":"2025-05-07T15:59:53.949055Z","shell.execute_reply.started":"2025-05-07T15:59:51.571319Z","shell.execute_reply":"2025-05-07T15:59:53.948229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Environments\n","metadata":{}},{"cell_type":"code","source":"%ls /kaggle/input/boltz-dependencies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T15:59:53.949942Z","iopub.execute_input":"2025-05-07T15:59:53.950367Z","iopub.status.idle":"2025-05-07T15:59:54.078254Z","shell.execute_reply.started":"2025-05-07T15:59:53.950341Z","shell.execute_reply":"2025-05-07T15:59:54.077059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --no-index /kaggle/input/boltz-dependencies/*whl --no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T15:59:54.080485Z","iopub.execute_input":"2025-05-07T15:59:54.080838Z","iopub.status.idle":"2025-05-07T16:00:02.078812Z","shell.execute_reply.started":"2025-05-07T15:59:54.080804Z","shell.execute_reply":"2025-05-07T16:00:02.077971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --no-index /kaggle/input/fairscale-0413/*whl --no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:02.080503Z","iopub.execute_input":"2025-05-07T16:00:02.080761Z","iopub.status.idle":"2025-05-07T16:00:03.326915Z","shell.execute_reply.started":"2025-05-07T16:00:02.080725Z","shell.execute_reply":"2025-05-07T16:00:03.325831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --no-index /kaggle/input/biopython/*whl --no-deps","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:03.327980Z","iopub.execute_input":"2025-05-07T16:00:03.328276Z","iopub.status.idle":"2025-05-07T16:00:05.388902Z","shell.execute_reply.started":"2025-05-07T16:00:03.328253Z","shell.execute_reply":"2025-05-07T16:00:05.387868Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare scripts","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:05.389937Z","iopub.execute_input":"2025-05-07T16:00:05.390161Z","iopub.status.idle":"2025-05-07T16:00:05.395514Z","shell.execute_reply.started":"2025-05-07T16:00:05.390142Z","shell.execute_reply":"2025-05-07T16:00:05.394710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%mkdir inputs_prediction\n%mkdir outputs_prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:05.396387Z","iopub.execute_input":"2025-05-07T16:00:05.396637Z","iopub.status.idle":"2025-05-07T16:00:05.637665Z","shell.execute_reply.started":"2025-05-07T16:00:05.396618Z","shell.execute_reply":"2025-05-07T16:00:05.636598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cp -rf /kaggle/input/rna-prediction-boltz/boltz/src/boltz .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:05.638725Z","iopub.execute_input":"2025-05-07T16:00:05.639066Z","iopub.status.idle":"2025-05-07T16:00:06.279639Z","shell.execute_reply.started":"2025-05-07T16:00:05.639040Z","shell.execute_reply":"2025-05-07T16:00:06.278786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls boltz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.282514Z","iopub.execute_input":"2025-05-07T16:00:06.282799Z","iopub.status.idle":"2025-05-07T16:00:06.401636Z","shell.execute_reply.started":"2025-05-07T16:00:06.282767Z","shell.execute_reply":"2025-05-07T16:00:06.400963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Write file","metadata":{}},{"cell_type":"code","source":"%%writefile inference.py\n\nimport pickle\nimport urllib.request\nfrom dataclasses import asdict, dataclass\nfrom pathlib import Path\nfrom typing import Literal, Optional\n\nimport click\nimport torch\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning.strategies import DDPStrategy\nfrom pytorch_lightning.utilities import rank_zero_only\nfrom tqdm import tqdm\n\nfrom boltz.data import const\nfrom boltz.data.module.inference import BoltzInferenceDataModule\nfrom boltz.data.msa.mmseqs2 import run_mmseqs2\nfrom boltz.data.parse.a3m import parse_a3m\nfrom boltz.data.parse.csv import parse_csv\nfrom boltz.data.parse.fasta import parse_fasta\nfrom boltz.data.parse.yaml import parse_yaml\nfrom boltz.data.types import MSA, Manifest, Record\nfrom boltz.data.write.writer import BoltzWriter\nfrom boltz.model.model import Boltz1\n\nCCD_URL = \"https://huggingface.co/boltz-community/boltz-1/resolve/main/ccd.pkl\"\nMODEL_URL = (\n    \"https://huggingface.co/boltz-community/boltz-1/resolve/main/boltz1_conf.ckpt\"\n)\n\n\n@dataclass\nclass BoltzProcessedInput:\n    \"\"\"Processed input data.\"\"\"\n\n    manifest: Manifest\n    targets_dir: Path\n    msa_dir: Path\n\n\n@dataclass\nclass BoltzDiffusionParams:\n    \"\"\"Diffusion process parameters.\"\"\"\n\n    gamma_0: float = 0.605\n    gamma_min: float = 1.107\n    noise_scale: float = 0.901\n    rho: float = 8\n    step_scale: float = 1.638\n    sigma_min: float = 0.0004\n    sigma_max: float = 160.0\n    sigma_data: float = 16.0\n    P_mean: float = -1.2\n    P_std: float = 1.5\n    coordinate_augmentation: bool = True\n    alignment_reverse_diff: bool = True\n    synchronize_sigmas: bool = True\n    use_inference_model_cache: bool = True\n\n\n@rank_zero_only\ndef download(cache: Path) -> None:\n    \"\"\"Download all the required data.\n\n    Parameters\n    ----------\n    cache : Path\n        The cache directory.\n\n    \"\"\"\n    # Download CCD\n    ccd = cache / \"ccd.pkl\"\n    if not ccd.exists():\n        click.echo(\n            f\"Downloading the CCD dictionary to {ccd}. You may \"\n            \"change the cache directory with the --cache flag.\"\n        )\n        urllib.request.urlretrieve(CCD_URL, str(ccd))  # noqa: S310\n\n    # Download model\n    model = cache / \"boltz1_conf.ckpt\"\n    if not model.exists():\n        click.echo(\n            f\"Downloading the model weights to {model}. You may \"\n            \"change the cache directory with the --cache flag.\"\n        )\n        urllib.request.urlretrieve(MODEL_URL, str(model))  # noqa: S310\n\n\ndef check_inputs(\n    data: Path,\n    outdir: Path,\n    override: bool = False,\n) -> list[Path]:\n    \"\"\"Check the input data and output directory.\n\n    If the input data is a directory, it will be expanded\n    to all files in this directory. Then, we check if there\n    are any existing predictions and remove them from the\n    list of input data, unless the override flag is set.\n\n    Parameters\n    ----------\n    data : Path\n        The input data.\n    outdir : Path\n        The output directory.\n    override: bool\n        Whether to override existing predictions.\n\n    Returns\n    -------\n    list[Path]\n        The list of input data.\n\n    \"\"\"\n    click.echo(\"Checking input data.\")\n\n    # Check if data is a directory\n    if data.is_dir():\n        data: list[Path] = list(data.glob(\"*\"))\n\n        # Filter out non .fasta or .yaml files, raise\n        # an error on directory and other file types\n        filtered_data = []\n        for d in data:\n            if d.suffix in (\".fa\", \".fas\", \".fasta\", \".yml\", \".yaml\"):\n                filtered_data.append(d)\n            elif d.is_dir():\n                msg = f\"Found directory {d} instead of .fasta or .yaml.\"\n                raise RuntimeError(msg)\n            else:\n                msg = (\n                    f\"Unable to parse filetype {d.suffix}, \"\n                    \"please provide a .fasta or .yaml file.\"\n                )\n                raise RuntimeError(msg)\n\n        data = filtered_data\n    else:\n        data = [data]\n\n    # Check if existing predictions are found\n    existing = (outdir / \"predictions\").rglob(\"*\")\n    existing = {e.name for e in existing if e.is_dir()}\n\n    # Remove them from the input data\n    if existing and not override:\n        data = [d for d in data if d.stem not in existing]\n        num_skipped = len(existing) - len(data)\n        msg = (\n            f\"Found some existing predictions ({num_skipped}), \"\n            f\"skipping and running only the missing ones, \"\n            \"if any. If you wish to override these existing \"\n            \"predictions, please set the --override flag.\"\n        )\n        click.echo(msg)\n    elif existing and override:\n        msg = \"Found existing predictions, will override.\"\n        click.echo(msg)\n\n    return data\n\n\ndef compute_msa(\n    data: dict[str, str],\n    target_id: str,\n    msa_dir: Path,\n    msa_server_url: str,\n    msa_pairing_strategy: str,\n) -> None:\n    \"\"\"Compute the MSA for the input data.\n\n    Parameters\n    ----------\n    data : dict[str, str]\n        The input protein sequences.\n    target_id : str\n        The target id.\n    msa_dir : Path\n        The msa directory.\n    msa_server_url : str\n        The MSA server URL.\n    msa_pairing_strategy : str\n        The MSA pairing strategy.\n\n    \"\"\"\n    if len(data) > 1:\n        paired_msas = run_mmseqs2(\n            list(data.values()),\n            msa_dir / f\"{target_id}_paired_tmp\",\n            use_env=True,\n            use_pairing=True,\n            host_url=msa_server_url,\n            pairing_strategy=msa_pairing_strategy,\n        )\n    else:\n        paired_msas = [\"\"] * len(data)\n\n    unpaired_msa = run_mmseqs2(\n        list(data.values()),\n        msa_dir / f\"{target_id}_unpaired_tmp\",\n        use_env=True,\n        use_pairing=False,\n        host_url=msa_server_url,\n        pairing_strategy=msa_pairing_strategy,\n    )\n\n    for idx, name in enumerate(data):\n        # Get paired sequences\n        paired = paired_msas[idx].strip().splitlines()\n        paired = paired[1::2]  # ignore headers\n        paired = paired[: const.max_paired_seqs]\n\n        # Set key per row and remove empty sequences\n        keys = [idx for idx, s in enumerate(paired) if s != \"-\" * len(s)]\n        paired = [s for s in paired if s != \"-\" * len(s)]\n\n        # Combine paired-unpaired sequences\n        unpaired = unpaired_msa[idx].strip().splitlines()\n        unpaired = unpaired[1::2]\n        unpaired = unpaired[: (const.max_msa_seqs - len(paired))]\n        if paired:\n            unpaired = unpaired[1:]  # ignore query is already present\n\n        # Combine\n        seqs = paired + unpaired\n        keys = keys + [-1] * len(unpaired)\n\n        # Dump MSA\n        csv_str = [\"key,sequence\"] + [f\"{key},{seq}\" for key, seq in zip(keys, seqs)]\n\n        msa_path = msa_dir / f\"{name}.csv\"\n        with msa_path.open(\"w\") as f:\n            f.write(\"\\n\".join(csv_str))\n\n\n@rank_zero_only\ndef process_inputs(  # noqa: C901, PLR0912, PLR0915\n    data: list[Path],\n    out_dir: Path,\n    ccd_path: Path,\n    msa_server_url: str,\n    msa_pairing_strategy: str,\n    max_msa_seqs: int = 4096,\n    use_msa_server: bool = False,\n) -> None:\n    \"\"\"Process the input data and output directory.\n\n    Parameters\n    ----------\n    data : list[Path]\n        The input data.\n    out_dir : Path\n        The output directory.\n    ccd_path : Path\n        The path to the CCD dictionary.\n    max_msa_seqs : int, optional\n        Max number of MSA sequences, by default 4096.\n    use_msa_server : bool, optional\n        Whether to use the MMSeqs2 server for MSA generation, by default False.\n\n    Returns\n    -------\n    BoltzProcessedInput\n        The processed input data.\n\n    \"\"\"\n    click.echo(\"Processing input data.\")\n    existing_records = None\n\n    # Check if manifest exists at output path\n    manifest_path = out_dir / \"processed\" / \"manifest.json\"\n    if manifest_path.exists():\n        click.echo(f\"Found a manifest file at output directory: {out_dir}\")\n\n        manifest: Manifest = Manifest.load(manifest_path)\n        input_ids = [d.stem for d in data]\n        existing_records, processed_ids = zip(\n            *[\n                (record, record.id)\n                for record in manifest.records\n                if record.id in input_ids\n            ]\n        )\n\n        if isinstance(existing_records, tuple):\n            existing_records = list(existing_records)\n\n        # Check how many examples need to be processed\n        missing = len(input_ids) - len(processed_ids)\n        if not missing:\n            click.echo(\"All examples in data are processed. Updating the manifest\")\n            # Dump updated manifest\n            updated_manifest = Manifest(existing_records)\n            updated_manifest.dump(out_dir / \"processed\" / \"manifest.json\")\n            return\n\n        click.echo(f\"{missing} missing ids. Preprocessing these ids\")\n        missing_ids = list(set(input_ids).difference(set(processed_ids)))\n        data = [d for d in data if d.stem in missing_ids]\n        assert len(data) == len(missing_ids)\n\n    # Create output directories\n    msa_dir = out_dir / \"msa\"\n    structure_dir = out_dir / \"processed\" / \"structures\"\n    processed_msa_dir = out_dir / \"processed\" / \"msa\"\n    predictions_dir = out_dir / \"predictions\"\n\n    out_dir.mkdir(parents=True, exist_ok=True)\n    msa_dir.mkdir(parents=True, exist_ok=True)\n    structure_dir.mkdir(parents=True, exist_ok=True)\n    processed_msa_dir.mkdir(parents=True, exist_ok=True)\n    predictions_dir.mkdir(parents=True, exist_ok=True)\n\n    # Load CCD\n    with ccd_path.open(\"rb\") as file:\n        ccd = pickle.load(file)  # noqa: S301\n\n    if existing_records is not None:\n        click.echo(f\"Found {len(existing_records)} records. Adding them to records\")\n\n    # Parse input data\n    records: list[Record] = existing_records if existing_records is not None else []\n    for path in tqdm(data):\n        try:\n            # Parse data\n            if path.suffix in (\".fa\", \".fas\", \".fasta\"):\n                target = parse_fasta(path, ccd)\n            elif path.suffix in (\".yml\", \".yaml\"):\n                target = parse_yaml(path, ccd)\n            elif path.is_dir():\n                msg = f\"Found directory {path} instead of .fasta or .yaml, skipping.\"\n                raise RuntimeError(msg)\n            else:\n                msg = (\n                    f\"Unable to parse filetype {path.suffix}, \"\n                    \"please provide a .fasta or .yaml file.\"\n                )\n                raise RuntimeError(msg)\n\n            # Get target id\n            target_id = target.record.id\n\n            # Get all MSA ids and decide whether to generate MSA\n            to_generate = {}\n            prot_id = const.chain_type_ids[\"PROTEIN\"]\n            for chain in target.record.chains:\n                # Add to generate list, assigning entity id\n                if (chain.mol_type == prot_id) and (chain.msa_id == 0):\n                    entity_id = chain.entity_id\n                    msa_id = f\"{target_id}_{entity_id}\"\n                    to_generate[msa_id] = target.sequences[entity_id]\n                    chain.msa_id = msa_dir / f\"{msa_id}.csv\"\n\n                # We do not support msa generation for non-protein chains\n                elif chain.msa_id == 0:\n                    chain.msa_id = -1\n\n            # Generate MSA\n            if to_generate and not use_msa_server:\n                msg = \"Missing MSA's in input and --use_msa_server flag not set.\"\n                raise RuntimeError(msg)\n\n            if to_generate:\n                msg = f\"Generating MSA for {path} with {len(to_generate)} protein entities.\"\n                click.echo(msg)\n                compute_msa(\n                    data=to_generate,\n                    target_id=target_id,\n                    msa_dir=msa_dir,\n                    msa_server_url=msa_server_url,\n                    msa_pairing_strategy=msa_pairing_strategy,\n                )\n\n            # Parse MSA data\n            msas = sorted({c.msa_id for c in target.record.chains if c.msa_id != -1})\n            msa_id_map = {}\n            for msa_idx, msa_id in enumerate(msas):\n                # Check that raw MSA exists\n                msa_path = Path(msa_id)\n                if not msa_path.exists():\n                    msg = f\"MSA file {msa_path} not found.\"\n                    raise FileNotFoundError(msg)\n\n                # Dump processed MSA\n                processed = processed_msa_dir / f\"{target_id}_{msa_idx}.npz\"\n                msa_id_map[msa_id] = f\"{target_id}_{msa_idx}\"\n                if not processed.exists():\n                    # Parse A3M\n                    if msa_path.suffix == \".a3m\":\n                        msa: MSA = parse_a3m(\n                            msa_path,\n                            taxonomy=None,\n                            max_seqs=max_msa_seqs,\n                        )\n                    elif msa_path.suffix == \".csv\":\n                        msa: MSA = parse_csv(msa_path, max_seqs=max_msa_seqs)\n                    else:\n                        msg = f\"MSA file {msa_path} not supported, only a3m or csv.\"\n                        raise RuntimeError(msg)\n\n                    msa.dump(processed)\n\n            # Modify records to point to processed MSA\n            for c in target.record.chains:\n                if (c.msa_id != -1) and (c.msa_id in msa_id_map):\n                    c.msa_id = msa_id_map[c.msa_id]\n\n            # Keep record\n            records.append(target.record)\n\n            # Dump structure\n            struct_path = structure_dir / f\"{target.record.id}.npz\"\n            target.structure.dump(struct_path)\n\n        except Exception as e:\n            if len(data) > 1:\n                print(f\"Failed to process {path}. Skipping. Error: {e}.\")\n            else:\n                raise e\n\n    # Dump manifest\n    manifest = Manifest(records)\n    manifest.dump(out_dir / \"processed\" / \"manifest.json\")\n\ndef predict(\n    data: str,\n    out_dir: str,\n    cache: str = \"~/.boltz\",\n    checkpoint: Optional[str] = None,\n    devices: int = 1,\n    accelerator: str = \"gpu\",\n    recycling_steps: int = 3,\n    sampling_steps: int = 200,\n    diffusion_samples: int = 1,\n    step_scale: float = 1.638,\n    write_full_pae: bool = False,\n    write_full_pde: bool = False,\n    output_format: Literal[\"pdb\", \"mmcif\"] = \"mmcif\",\n    num_workers: int = 2,\n    override: bool = False,\n    seed: Optional[int] = None,\n    use_msa_server: bool = False,\n    msa_server_url: str = \"https://api.colabfold.com\",\n    msa_pairing_strategy: str = \"greedy\",\n) -> None:\n    \"\"\"Run predictions with Boltz-1.\"\"\"\n    # If cpu, write a friendly warning\n    if accelerator == \"cpu\":\n        msg = \"Running on CPU, this will be slow. Consider using a GPU.\"\n        click.echo(msg)\n\n    # Set no grad\n    torch.set_grad_enabled(False)\n\n    # Ignore matmul precision warning\n    torch.set_float32_matmul_precision(\"highest\")\n\n    # Set seed if desired\n    if seed is not None:\n        seed_everything(int(seed))\n\n    # Set cache path\n    cache = Path(cache).expanduser()\n    cache.mkdir(parents=True, exist_ok=True)\n\n    # Create output directories\n    data = Path(data).expanduser()\n    out_dir = Path(out_dir).expanduser()\n    out_dir = out_dir / f\"boltz_results_{data.stem}\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n\n    # Download necessary data and model\n    download(cache)\n\n    # Validate inputs\n    data = check_inputs(data, out_dir, override)\n    if not data:\n        click.echo(\"No predictions to run, exiting.\")\n        return\n\n    # Set up trainer\n    strategy = \"auto\"\n    if (isinstance(devices, int) and devices > 1) or (\n        isinstance(devices, list) and len(devices) > 1\n    ):\n        strategy = DDPStrategy()\n        if len(data) < devices:\n            msg = (\n                \"Number of requested devices is greater \"\n                \"than the number of predictions.\"\n            )\n            raise ValueError(msg)\n\n    msg = f\"Running predictions for {len(data)} structure\"\n    msg += \"s\" if len(data) > 1 else \"\"\n    click.echo(msg)\n\n    # Process inputs\n    ccd_path = cache / \"ccd.pkl\"\n    process_inputs(\n        data=data,\n        out_dir=out_dir,\n        ccd_path=ccd_path,\n        use_msa_server=use_msa_server,\n        msa_server_url=msa_server_url,\n        msa_pairing_strategy=msa_pairing_strategy,\n    )\n\n    # Load processed data\n    processed_dir = out_dir / \"processed\"\n    processed = BoltzProcessedInput(\n        manifest=Manifest.load(processed_dir / \"manifest.json\"),\n        targets_dir=processed_dir / \"structures\",\n        msa_dir=processed_dir / \"msa\",\n    )\n\n    # Create data module\n    data_module = BoltzInferenceDataModule(\n        manifest=processed.manifest,\n        target_dir=processed.targets_dir,\n        msa_dir=processed.msa_dir,\n        num_workers=num_workers,\n    )\n\n    # Load model\n    if checkpoint is None:\n        checkpoint = cache / \"boltz1_conf.ckpt\"\n\n    predict_args = {\n        \"recycling_steps\": recycling_steps,\n        \"sampling_steps\": sampling_steps,\n        \"diffusion_samples\": diffusion_samples,\n        \"write_confidence_summary\": True,\n        \"write_full_pae\": write_full_pae,\n        \"write_full_pde\": write_full_pde,\n    }\n    diffusion_params = BoltzDiffusionParams()\n    diffusion_params.step_scale = step_scale\n    model_module: Boltz1 = Boltz1.load_from_checkpoint(\n        checkpoint,\n        strict=True,\n        predict_args=predict_args,\n        map_location=\"cpu\",\n        diffusion_process_args=asdict(diffusion_params),\n        ema=False,\n    )\n    model_module.eval()\n\n    # Create prediction writer\n    pred_writer = BoltzWriter(\n        data_dir=processed.targets_dir,\n        output_dir=out_dir / \"predictions\",\n        output_format=output_format,\n    )\n\n    trainer = Trainer(\n        default_root_dir=out_dir,\n        strategy=strategy,\n        callbacks=[pred_writer],\n        accelerator=accelerator,\n        devices=devices,\n        precision=32,\n    )\n\n    # Compute predictions\n    trainer.predict(\n        model_module,\n        datamodule=data_module,\n        return_predictions=False,\n    )\n\n\nif __name__ == \"__main__\":\n    predict(data=\"./inputs_prediction\",\n            out_dir=\"./outputs_prediction\",\n            cache=\"/kaggle/input/rna-prediction-boltz/\",\n            diffusion_samples=5,\n            seed=42,\n            override=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.403397Z","iopub.execute_input":"2025-05-07T16:00:06.403609Z","iopub.status.idle":"2025-05-07T16:00:06.411592Z","shell.execute_reply.started":"2025-05-07T16:00:06.403591Z","shell.execute_reply":"2025-05-07T16:00:06.410970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare inputs","metadata":{}},{"cell_type":"code","source":"sub_file = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n\nsub_file.head()\n\nnames = sub_file['target_id'].tolist()\nsequences = sub_file['sequence'].tolist()\n\n# Inference\nidx = 0 \nfor tmp_id, tmp_sequence in zip(names, sequences):\n    with open(f'/kaggle/working/inputs_prediction/{tmp_id}.yaml', 'w') as f:\n        f.write(\"constraints: []\\n\")\n        f.write(\"sequences:\\n\")\n        f.write(\"- rna:\\n\")\n        f.write(\"    id:\\n\")\n        f.write(\"    - A1\\n\")\n        f.write(f\"    sequence: {tmp_sequence}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.412383Z","iopub.execute_input":"2025-05-07T16:00:06.412572Z","iopub.status.idle":"2025-05-07T16:00:06.442665Z","shell.execute_reply.started":"2025-05-07T16:00:06.412555Z","shell.execute_reply":"2025-05-07T16:00:06.442099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls inputs_prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.443425Z","iopub.execute_input":"2025-05-07T16:00:06.443616Z","iopub.status.idle":"2025-05-07T16:00:06.560176Z","shell.execute_reply.started":"2025-05-07T16:00:06.443599Z","shell.execute_reply":"2025-05-07T16:00:06.559434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls outputs_prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.561129Z","iopub.execute_input":"2025-05-07T16:00:06.561430Z","iopub.status.idle":"2025-05-07T16:00:06.678658Z","shell.execute_reply.started":"2025-05-07T16:00:06.561400Z","shell.execute_reply":"2025-05-07T16:00:06.677777Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exec inference","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:06.679570Z","iopub.execute_input":"2025-05-07T16:00:06.679821Z","iopub.status.idle":"2025-05-07T16:00:09.781807Z","shell.execute_reply.started":"2025-05-07T16:00:06.679801Z","shell.execute_reply":"2025-05-07T16:00:09.780917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\nimport gc\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:09.782606Z","iopub.execute_input":"2025-05-07T16:00:09.783116Z","iopub.status.idle":"2025-05-07T16:00:09.883099Z","shell.execute_reply.started":"2025-05-07T16:00:09.783088Z","shell.execute_reply":"2025-05-07T16:00:09.882389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nresult = subprocess.run(['python', 'inference.py'], capture_output=True, text=True)\nlogger.info(f\"Command output: {result.stdout}\")\nlogger.error(f\"Command error: {result.stderr}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:00:09.883894Z","iopub.execute_input":"2025-05-07T16:00:09.884111Z","iopub.status.idle":"2025-05-07T16:18:52.881736Z","shell.execute_reply.started":"2025-05-07T16:00:09.884093Z","shell.execute_reply":"2025-05-07T16:18:52.880837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Read RNA files","metadata":{}},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:52.882779Z","iopub.execute_input":"2025-05-07T16:18:52.883081Z","iopub.status.idle":"2025-05-07T16:18:52.887558Z","shell.execute_reply.started":"2025-05-07T16:18:52.883050Z","shell.execute_reply":"2025-05-07T16:18:52.886922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Gather results","metadata":{"execution":{"iopub.status.busy":"2025-03-04T21:51:26.943982Z","iopub.execute_input":"2025-03-04T21:51:26.94429Z","iopub.status.idle":"2025-03-04T21:51:26.949385Z","shell.execute_reply.started":"2025-03-04T21:51:26.944265Z","shell.execute_reply":"2025-03-04T21:51:26.948635Z"}}},{"cell_type":"code","source":"from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n\ndef get_coords(tmp_id, idx):\n    cif_file = f\"outputs_prediction/boltz_results_inputs_prediction/predictions/{tmp_id}/{tmp_id}_model_{idx}.cif\"\n\n    mmcif_dict = MMCIF2Dict(cif_file)\n    \n    entity_poly_seq = mmcif_dict.get(\"_entity_poly_seq.mon_id\", [])\n    sequence = \"\".join(entity_poly_seq)\n    print(\"RNA sequence:\", sequence)\n    \n    x_coords = mmcif_dict[\"_atom_site.Cartn_x\"]\n    y_coords = mmcif_dict[\"_atom_site.Cartn_y\"]\n    z_coords = mmcif_dict[\"_atom_site.Cartn_z\"]\n    atom_names = mmcif_dict[\"_atom_site.label_atom_id\"]\n    \n    c1_coords = []\n    for i, atom in enumerate(atom_names):\n        if atom == \"C1'\":\n            c1_coords.append((float(x_coords[i]), float(y_coords[i]), float(z_coords[i])))\n    return c1_coords\n\nall_preds = os.listdir('outputs_prediction/boltz_results_inputs_prediction/predictions')\nsubmission = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:52.888433Z","iopub.execute_input":"2025-05-07T16:18:52.888720Z","iopub.status.idle":"2025-05-07T16:18:52.968908Z","shell.execute_reply.started":"2025-05-07T16:18:52.888692Z","shell.execute_reply":"2025-05-07T16:18:52.968319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"idx = 0\nfor tmp_id in all_preds:\n    print('#'*20, f'inferences for {tmp_id}')\n    for idx in range(5):\n        c1_coords = get_coords(tmp_id, idx)\n        submission.loc[submission['ID'].apply(lambda x: tmp_id in x), [f'x_{idx+1}', f'y_{idx+1}', f'z_{idx+1}']] = c1_coords\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:52.969538Z","iopub.execute_input":"2025-05-07T16:18:52.969718Z","iopub.status.idle":"2025-05-07T16:18:59.445087Z","shell.execute_reply.started":"2025-05-07T16:18:52.969701Z","shell.execute_reply":"2025-05-07T16:18:59.444215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:59.445984Z","iopub.execute_input":"2025-05-07T16:18:59.446298Z","iopub.status.idle":"2025-05-07T16:18:59.574605Z","shell.execute_reply.started":"2025-05-07T16:18:59.446266Z","shell.execute_reply":"2025-05-07T16:18:59.573548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -rf boltz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:59.575763Z","iopub.execute_input":"2025-05-07T16:18:59.576113Z","iopub.status.idle":"2025-05-07T16:18:59.707169Z","shell.execute_reply.started":"2025-05-07T16:18:59.576076Z","shell.execute_reply":"2025-05-07T16:18:59.706096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -rf inputs_prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:59.708252Z","iopub.execute_input":"2025-05-07T16:18:59.708573Z","iopub.status.idle":"2025-05-07T16:18:59.833840Z","shell.execute_reply.started":"2025-05-07T16:18:59.708543Z","shell.execute_reply":"2025-05-07T16:18:59.832933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -rf outputs_prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:59.834816Z","iopub.execute_input":"2025-05-07T16:18:59.835052Z","iopub.status.idle":"2025-05-07T16:18:59.971259Z","shell.execute_reply.started":"2025-05-07T16:18:59.835032Z","shell.execute_reply":"2025-05-07T16:18:59.970004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%rm -rf inference.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:18:59.972328Z","iopub.execute_input":"2025-05-07T16:18:59.972565Z","iopub.status.idle":"2025-05-07T16:19:00.098096Z","shell.execute_reply.started":"2025-05-07T16:18:59.972542Z","shell.execute_reply":"2025-05-07T16:19:00.097202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:19:00.099071Z","iopub.execute_input":"2025-05-07T16:19:00.099326Z","iopub.status.idle":"2025-05-07T16:19:00.225070Z","shell.execute_reply.started":"2025-05-07T16:19:00.099306Z","shell.execute_reply":"2025-05-07T16:19:00.224059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:19:00.226103Z","iopub.execute_input":"2025-05-07T16:19:00.226361Z","iopub.status.idle":"2025-05-07T16:19:00.273139Z","shell.execute_reply.started":"2025-05-07T16:19:00.226340Z","shell.execute_reply":"2025-05-07T16:19:00.272558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:19:00.276427Z","iopub.execute_input":"2025-05-07T16:19:00.276621Z","iopub.status.idle":"2025-05-07T16:19:00.401099Z","shell.execute_reply.started":"2025-05-07T16:19:00.276604Z","shell.execute_reply":"2025-05-07T16:19:00.400094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission['target_id'] = submission['ID'].apply(lambda x: x.split('_')[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:19:00.402458Z","iopub.execute_input":"2025-05-07T16:19:00.402843Z","iopub.status.idle":"2025-05-07T16:19:00.409837Z","shell.execute_reply.started":"2025-05-07T16:19:00.402818Z","shell.execute_reply":"2025-05-07T16:19:00.409039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.groupby('target_id')['x_1'].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T16:19:00.410787Z","iopub.execute_input":"2025-05-07T16:19:00.411116Z","iopub.status.idle":"2025-05-07T16:19:00.435389Z","shell.execute_reply.started":"2025-05-07T16:19:00.411087Z","shell.execute_reply":"2025-05-07T16:19:00.434612Z"}},"outputs":[],"execution_count":null}]}